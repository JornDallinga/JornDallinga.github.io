---
title: "Proba-V"
author: "Jorn Dallinga, PROBA-V package used from Johannes Eberenz"
date: "`r format(Sys.time(), '%d %B, %Y')`"
Version: "0.4 (updated 28-9)"
output:
  knitrBootstrap::bootstrap_document:
    title: "ProbaV" 
    theme: cosmo
    menu: FALSE
---

#WUR PROBA-V workflow ![WUR logo](http://www.wageningenur.nl/upload/f9a0b5f2-15c5-4b84-9e14-20ef02f5e265_wur-logo.png)

```{r, echo=FALSE, message=FALSE}
library(knitr)
opts_chunk$set(fig.width=5, fig.align='center', fig.height=5, dpi=72)
# set the knitR working directory to the same file location as getwd(), in order to maintain the link to R source scripts.
knitr::opts_knit$set(root.dir = "/home/pi/PROBA_V/ProbaV_JD")
```

## Introduction

the PROBA-V instrument

ESA is currently preparing the launch of the Sentinel-3 satellites, of which the first one (Sentinel-3A) is foreseen for September 29tn, 2015. The Sentinel missions are developed for the operational needs in land, ocean, and atmospheric monitoring within the European Copernicus programme. However, between the end-of-life of SPOT-VGT and the launch of the Sentinel-3 satellites, a rather large time gap of about 3 years would occur, which would imply a discontinuation of the vegetation monitoring time series.

In order to preserve this observational continuity, Belgium decided to build a small satellite mission based on the successful ESA PROBA expertise, using state-of-the-art-technology. PROBA-V (with "V" standing for Vegetation) was designed by a full Belgian consortium, fulfills all of the vegetation users specifications and is complement to the Sentinel-3 satellites to be launched after PROBA-V.

PROBA-V has a constellation of 3 cameras that daily observe the land surface and vegetation at similar spectral wavelengths (BLUE, RED, NIR, and SWIR) as SPOT-VGT, but with an improved spatial resolution (300 m and 100 m for the centre camera). These observations are processed into daily and 10-daily syntheses products,  available at 100 m, 300 m, and 1 km. The products can be downloaded from [vito](www.vito-eodata.be). [source quoted directly](http://proba-v.vgt.vito.be/) 

## Preperation

This script has been tested and runs on a LINUX Centos machine located on the ESA cloud toolbox, but might require some tweaking if used on other OS or versions. Most functions are designed to run parallel on multi-core machines, such as the cloud toolbox. Al though this example script uses a small case study throughout the tutorial, when extending the functions to larger areas, system time could become significantly slower (depending on how many cores you have to your disposal).

System on which the script has been tested:
```{r, echo=F, results= 'hold'}
Sys.info()['sysname']
.Platform$OS.type
version$os
```

The data used within these scripts can be downloaded from the [vito](http://proba-v.vgt.vito.be/) website. Lets start with loading the required libraries and packages to illustrate a workflow on working with the PROBA-V data. Additionally, we have to set the library path if this has not been set previously. When working from the cloud toolbox, errors could occur with loading packages when the library path has not been added.

```{r, message=F, warning=F}
# add additional libary path
.libPaths( c( .libPaths(), "~/R/x86_64-redhat-linux-gnu-library/3.2") )

## libaries
library(ranger)
library(raster)
library(ggvis)
library(rgdal)
library(dplyr)
library(devtools)
library(gdalUtils)
library(probaV)
library(tools)
library(parallel)
library(zoo)
```


```{r, message=F, warning=F, eval=F}
# below the fixed link file in order to load the ProbaV package from Johannes
source("R/processProbaVbatch2.R")
source("R/getHarmMetricsSpatial_JE.R")
source("R/CleanProbaV2.R")
source("R/timeVrtProbaV2.R")
source("R/cloud_filter.R")
```

The Proba-V package used can be viewed [here](https://github.com/johanez/probaV). Many fixes, including spelling, and further updating of the package is still underway. Therefore, we download and source the fixed scripts directly using the following 'source_ttps' function from another github repository. 

```{r,echo=T, results='hide'}
source_https <- function(url, ...) {
  # load package
  require(RCurl)
 
  # parse and evaluate each .R script
  sapply(c(url, ...), function(u) {
    eval(parse(text = getURL(u, followlocation = TRUE, cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl"))), envir = .GlobalEnv)
  })
}

source_https("https://raw.githubusercontent.com/JornDallinga/ProbaV_JD/master/R/processProbaVbatch2.R",
             "https://raw.githubusercontent.com/JornDallinga/ProbaV_JD/master/R/getHarmMetricsSpatial_JE.R",
             "https://raw.githubusercontent.com/JornDallinga/ProbaV_JD/master/R/CleanProbaV2.R",
             "https://raw.githubusercontent.com/JornDallinga/ProbaV_JD/master/R/timeVrtProbaV2.R",
             "https://raw.githubusercontent.com/JornDallinga/ProbaV_JD/master/R/cloud_filter.R")
```

## Data download

This example script uses data existing on the cloud toolbox and follows an existing directory structure. Downloading ProvaV data will not create that directory structure yet. Thus, this script will work when following the ProbaV directory structure on the cloud toolbox, but not yet with downloading the data manually to a certain directory. But if you would like to know how to download the ProbaV data, below follows an example.
Lets download the PROBA-V tiles by using coordinates! 

```{r}
# Select the location for which you wish to download the PROBA-V  tiles for. 
x <- 10.00 # Longitude
y <- 8.00 # Latitude

# In order to download the correct tile numbers, we use coordinates to convert to the tile number
tile <- probaVTileFromCoords(x, y)
tile_str <- paste("\'*",tile,"*\'", sep ="")

```

To download data from the PROBA-V vito website, we need to be a registerd user (free). If you dont allready have an account, feel free to make one by following this [link](http://www.vito-eodata.be/PDF/portal/Application.html#Home). Assign the username and password to a variable, which you can enter below.

```{r, results='hide'}
u_name <- readline("Type the username:")
p_word <- readline("Type the password:")
```
```{r}
# enter the file directory for the download location
dirloc <- paste(getwd(), '/2015/', sep = "")
# Create file directory if it does not exist yet
dir.create(file.path(dirloc), showWarnings = FALSE)
```

Use wget to download the data. wget has be passed directly in the terminal. Therefore, we pass the string to the system command. In this example, the link in the string will have to be adjusted manually to your request. The dates at the end of the http adres below, allow you to download for a specific year, month and/or day. If you wish to download all ProbaV data for a specific year (e.g. 2016), then change the dates to '2016/?/?mode=tif'. The data will be downloaded into the directory set in the previous code (dirloc). For more examples on how to download ProbaV data on different operating systems, please follow this [link](http://www.vito-eodata.be/PDF/image/Data_pool_manual.pdf).

```{r}
wget_string <- paste('wget -A ', tile_str ,' .tif' , ' -P ', dirloc, ' --no-directories -r --user=', u_name,' --password=', p_word, ' http://www.vito-eodata.be/PDF/datapool/Free_Data/PROBA-V_100m/S5_TOC_100_m/2016/2/1/?mode=tif', sep="")

# check for output of the download string
print(wget_string)
```
```{r, eval=FALSE}
# pass the string to the terminal directly from R.
system(wget_string)
```

## Preprocessing

Lets start with the preprocessing of the data. Remember, the following parts of the script only work by following the ProbaV directory structure on the cloud toolbox. Provided by Vito or you can download manually, but the files should be stored in the folder structure used by vito (One folder per date contains files for all tiles).

```{r, echo=F}

# set your data path
l0_dir <- "/DATA/GEOTIFF/PROBAV_L3_S5_TOC_100M"
```

start by setting our data path which contains the downloaded files. The following section loops through the downloaded data folder and retrieves the product information, such as tiles and acquisition dates. Since the we only work with .tif files (for now), we add '.tif$' to the pattern selection.

```{r, eval=F}
# variable setting for data path
10_dir <- "set data path" 
# if you manually downloaded the data
10_dir <- dirloc
```
```{r}
df_probav_down <- getProbaVinfo(l0_dir, pattern = ".tif$")

# plot the retrieved data
df_probav_down %>% ggvis(x=~tile, fill=~band) %>% layer_bars()
```

## clean data 
The function 'getProbaVQClist' creates a dataframe of state mask (SM) codes based on the quality indicators in the Status Map dataset. It provides an overview of clear codes per channel. Explanation on these SM codes can be found in the [ProbaV Product User Manual](http://proba-v.vgt.vito.be/sites/default/files/PROBAV-Products_User_Manual_v1.2.pdf), which can also be downloaded directly from the Vito [website](http://www.vito-eodata.be/PDF/portal/Application.html#Home).

For clear pixel selection, we use the SM codes with 'clear_all', which means that a certain pixel is not marked as shadow, cloud, ice or sea. Additionally, it selects only the 'good' quality pixels of the radiometric bands (SWIR, NIR, RED, BLUE).

```{r}
# Top of dataframe showing SM codes. 
head(getProbaVQClist()$all_bits)
# Select quality control value with clear channels
QC_val <- getProbaVQClist()$clear_all
# The QC_val now stores the high quality value:
print(paste('The Quality control value: ',QC_val), sep = "")
```

The Radiometry brick contains 4 raster layers. Lets split the radiometry brick into single .tif layers (SWIR, NIR, RED, BLUE). You can select which tiles you would like to process. In this workflow, we are going to work with 3 bands, the Blue, SWIR and NDVI bands.

```{r}
# First, select the radiometry .tif files from the download folder and which tiles to use
patterns <- c('RADIOMETRY.tif$') # "NDVI.tif$"
tiles <- c("X18Y02") # c("X21Y06","X21Y07",...)

# Lets gather the information from the radiometry band using the variables assigned above. 
glimpse(getProbaVinfo(l0_dir, pattern = patterns, tiles = tiles))

#How many radiometry bands do we have of the assigned tiles?
df_in <- getProbaVinfo(l0_dir, pattern = patterns, tiles = tiles)
print(paste(nrow(df_in), " radiometry bands", sep = ""))
```

Next step is to keep the quality control values in the data which correspond to the QC_val as result of the 'getProbaVQClist' function. Lets test this on a single date/location. Select a RADIOMETRY.tif or NDVI.tif file from the downloaded data folder and assign it to a variable. 

```{r}
# Assign variable from the download location of your Geotiffs. Lets use the NDVI.
r <- paste(l0_dir, "/20151021/PROBAV_S5_TOC_20151021_100M_V001/PROBAV_S5_TOC_X18Y02_20151021_100M_V001_NDVI.tif", sep = "")

# Assign a file.path (including filename) to which we will write the cleaned data.
filename <- paste(getwd(),"/rsdata/probav/sm2/PROBAV_S5_TOC_X18Y02_20151021_100M_V001.tif", sep = "")
```
```{r, eval=F}
cleanProbaV2(f_data = r, filename=filename, QC_val = QC_val, fill=255, datatype="FLT4S", as.is = F, overwrite = T)
```

The result is a cleaned raster dataset (right) with only the quality control value (QC_val) selected.

```{r}
par(mfrow = c(1, 2))
plot(raster(r))
plot(raster(filename))
par(mfrow = c(1, 1))
```


## Proccessing a ProbaV bath
The processProbaVbatch function uses the cleanProbaV function on a whole 'batch' of data. The starting date parameter helps selecting at which starting point you wish clean the data. The function uses parallel processing, which is useful when the machine has multiple processors or/and cores. The processing time of the following functions thus depend on the process capacity of your machine. In order to process both the Radiometry and the NDVI datasets, we will have to run the processProbaVbath function twice, with different patterns.

```{r, eval=F}
# Create the required directories
dir.create("rsdata", showWarnings = FALSE)
dir.create("rsdata/probav", showWarnings = FALSE)
dir.create("rsdata/probav/sm2", showWarnings = FALSE)

# How many cores do we have:
detectCores(all.tests = FALSE, logical = TRUE)

# Select the patterns to match the .tif files you wish to process.
patterns <- c('RADIOMETRY.tif$') # or "NDVI.tif$"

# similar for NDVI
processProbaVbatch2(l0_dir, 
                    pattern = patterns, tiles = tiles, start_d = "2015-10-25", end_date = NULL,
                    QC_val = QC_val, outdir = file.path(paste0(getwd(),"/rsdata/probav/sm2", collapse ="")),
                    ncores = (detectCores(all.tests = FALSE, logical = TRUE)-1),
                    overwrite=F)


```

## Input check for next functions

The following section sets the required parameters for the next function, the 'virtual raster stack'. Most of the parameters are pretty basic, or are repeated here as reminder. 

```{r}
# ----- check input --- #
tn <- 1 # tile number (tn) 
# Select tiles of your study area. Multiple tiles can be coerced together. 
tiles <- c("X18Y02") # c("X18Y02", "X18Y03")
# set directory of the processed files as a result of the processProbaVbatch function
probav_sm_dir <- file.path(paste0(getwd(),"/rsdata/probav/sm2/", collapse =""))
```

Lets use the getProbaVinfo function again to visualize a certain tile data that we have.

```{r}
# lets retrieve information on the available data that we have selected by setting our parameters.
df_probav_sm <- getProbaVinfo(probav_sm_dir, pattern =  '_sm.tif$', tiles = tiles)
# visualize product information, such as bands and acquisition dates. 
glimpse(df_probav_sm)
```


```{r}
# ----- next parameters ----#
# read and assign the unique available bands to a variable
bands <-  df_probav_sm[df_probav_sm$date == df_probav_sm$date[1], 'band']
#unique(df_probav_sm$band)
# read and assign the acquisition dates to a variable
dates <-  df_probav_sm[df_probav_sm$band == bands[1], 'date']
# minrows is a parameter for the coming raster processing functions. It allows you to set the minimal rows that the coming calc functions will apply their algorithm on simultaneously.
minrows = 15
# check for available cores and set cores (minus 1)
mc.cores = detectCores(all.tests = FALSE, logical = TRUE)-1
# create directory for the log files
dir.create("rsdata/probav/logs", showWarnings = FALSE)
# set log name
logfile <- file.path(getwd(), paste0("rsdata/probav/logs/", tiles, ".log"))
# create directory for output results and temp raster results
dir.create("rsdata/probav/metrics", showWarnings = FALSE)
dir.create("rsdata/probav/temp", showWarnings = FALSE)
rasterOptions(todisk = F,
              tmpdir = file.path(paste0(getwd(),"/rsdata/probav/temp", collapse ="")))
```

Select bands:
Band selection for the the stacking of raster layers. For this tutorial, we use the BlUE, SWIR and NDVI bands for the classification. However, you can select any of the available bands from the PROBA-V sensor (e.g. including NIR/RED).

```{r}
# Select the bands to use in sequential functions
bands_select <- '(NDVI|SWIR|BLUE)' # e.g. '(BLUE|SWIR|NDVI)' or '(BLUE|SWIR)' or 'NDVI'
bands_select <- 'NDVI' # e.g. '(BLUE|SWIR|NDVI)' or '(BLUE|SWIR)' or 'NDVI'
# Include the .tif extension 
bands_sel <- paste(bands_select,'_sm.tif$', sep = "")
```

## virtual stack
Create a virtual stack from selected bands. The virtual raster stacking is an alternative to the more conventional raster layer stacking through [stack](https://www.rdocumentation.org/packages/raster/versions/2.5-8/topics/stack) or [brick](https://www.rdocumentation.org/packages/raster/versions/2.5-8/topics/brick). Virtual raster stacking is an R wrapper for the 'gdalbuildvrt' function that is part of the Geospatial Data Abstraction Library (GDAL). Opposed to raster::stack or raster::brick, the virtual rasterstack function creates a file (.vrt), linked to the filepath environment of selected datasets. Major benefit is that GDAL vrt was found to query faster than raster::stack.

```{r}
# --- build a vrt ---#
# check the gdal version installed on the machine
gdalinfo(version = T)

# create virtual raster stack output name
vrt_name <- file.path(getwd(), paste0("rsdata/probav/sm2/", tiles, "_",paste0(bands, collapse = "_"), ".vrt"))
```

The virtual raster function within the Proba-V package can create two outputs, a virtual raster stack, or a dataframe including the metadata of the included rasters. This preference can be set by the 'return_raster' variable. Other parameters within the function are the output name (vrt name). the tiles to stack and the available start and end date of the tile selection. We are selecting the whole availabe range of dates.

As can be observed from the dataframe output (df_probav_sm), we get to retrieve the metadata of our selection. 

```{r}
b_vrt <- timeVrtProbaV2(probav_sm_dir, pattern = bands_sel, vrt_name = vrt_name, tile = tiles[1], return_raster = T, start_date = "2015-09-26", end_date = "2015-10-26", te = c(5.996773,51.80702,6.468209,52.43639))
  
df_probav_sm <- timeVrtProbaV2(probav_sm_dir, pattern = bands_sel, vrt_name = vrt_name, tile = tiles[1], return_raster = F, start_date ="2014-02-10", end_date = "2015-10-26")

# returning first three rows of the created dataframe.
head(df_probav_sm, n=3)
```

set temp extent:
Since we are working with large tiles and the available cores and cpu depend on the machine you are working on, we reduce our working extent to a subset. Below a coordinate selection of a subset area within the Netherlands and Germany. These coordinates are linked to the tile selection. If you intend to follow this tutorial with different tiles, please use coordinates available within your selected tile extent. 

```{r}
xmin <- 5.996773 
xmax <- 6.468209
ymin <- 51.80702
ymax <- 52.43639
e <- extent(c(xmin,xmax,ymin,ymax))
```

Lets plot the individual bands from the first date from our virtual raster stack.

```{r}
b_vrt_s <- subset(b_vrt,1:length(bands))
plot(b_vrt_s)
```

## cloudfilter example

"Clouds in satellite observations obstruct the retrieval of vegetation parameters. Therefore a proper cloud screening is pivotal in the pre-processing of the various value-added products. The PROBA-V cloud detection algorithm is a modified version of the method applied to the SPOTVGT
BLUE and SWIR observations (Lissens et al., 2000). Using these band reflectances, two
separate cloud masks are created. The first (second) mask uses a BLUE (SWIR) band threshold with
an additional check at 300 m resolution on the SWIR (BLUE) band. The final cloud mask is a merge
of these two masking results. Compared to the SPOT-VGT cloud mask, some modifications were
necessary, because the assumption that clouds are observed at the same position in both the BLUE
and SWIR bands is no longer valid for PROBA-V, due to the observation time difference."  [source](http://proba-v.vgt.vito.be/sites/default/files/Product_User_Manual.pdf)p.17. 

In addition to the added cloud/shadow algorythm applied on the Proba-V products, the Proba-V R package adds an additional cloud filter which requires some mannual interpretation. The following section will visualize the difference between the cloud/shadow algorytm from Proba-V and the created cloud filter function in the Proba-V R package.

We will start of with a false color image of our subset area previous defined by the extent function. We will simply use all bands available. In order to create a false color image, we will have to rerun our processbatchfunction without filtering the cloud/shadow pixels.

```{r}
# Select all the bands for a false color image from the RADIOMETRY stack
bands_select <- '(BLUE|SWIR|NIR0|RED0)' 
bands_sel <- paste(bands_select,'_sm.tif$', sep = "")

# run process batch on the unfiltered data
# Here we change the QC_value to select all the cells, including the cloud values.
# Write the clouds to a new directory, so it wont mess up the original file
# Select one point in time, lets say: 2015-04-16

cloud_dir <- "rsdata/probav/sm_Withclouds"
dir.create(file.path(cloud_dir), showWarnings = FALSE)

# select dir with clouds
probav_cloud_dir <- paste(getwd(),'/',cloud_dir, sep = "")
```
```{r, eval=F}
# we wont use NDVI for the cloud filter in this example, just the radiometry is needed
patterns <- c('RADIOMETRY.tif$')
processProbaVbatch2(l0_dir, 
                    pattern = patterns, tiles = tiles, start_date = "2015-04-16", end_date = "2015-04-16",
                    QC_val = 1:255, outdir = file.path(paste0(getwd(),cloud_dir, collapse ="")),
                    ncores = (detectCores(all.tests = FALSE, logical = TRUE)-1),
                    overwrite=F)

```

Rerun the virtual stack function on our newly created directory with unfiltered data. Since we are working with a specific start and end date to visualize a false color image on a fixed time, we adjust our start and end date accordingly. 

```{r}
# select dir with clouds
probav_cloud_dir <- paste(getwd(),'/',cloud_dir,'/', sep = "")
# load the image in our virtual raster stack
b_vrt_cloud <- timeVrtProbaV2(probav_cloud_dir, pattern = bands_sel, vrt_name = vrt_name, tile = tiles, return_raster = T, start_date = "2015-04-16", end_date = "2015-04-16", te = c(5.996773,51.80702,6.468209,52.43639))

# plot a false color image
plotRGB(b_vrt_cloud, 3, 2, 1, stretch='lin')
```

Well that looks cloudy! Good, now we can start adding the Proba-V cloud mask and the Proba-V R package cloud filter. Lets start with visualizing the cloud detection method inbedded in the Proba-V data.

```{r}
# cloud mask SM
bands_select <- '(BLUE|SWIR|NIR0)' 
bands_sel <- paste(bands_select,'_sm.tif$', sep = "")

# load the image in our virtual raster stack
b_vrt_cloud_mask <- timeVrtProbaV2(probav_sm_dir, pattern = bands_sel, vrt_name = vrt_name, tile = tiles, return_raster = T, start_date = "2015-04-16", end_date = "2015-04-16", te = c(5.996773,51.80702,6.468209,52.43639))

# assign virtual raster stack to new variable
r <- b_vrt_cloud_mask
# copy data
r2 <- r
```

all NA values in our raster(r) are in this scene cloud pixels. We assign a value (9999) to these cloud pixels in order to visualize them against our cloud filter function later on. 

```{r}
r2[is.na(r)] <- 9999
r2[r2 < 9999] <- NA
r2 <- subset(r2,1)
```

Lets plot the original cloud detection method inbedded within the ProbaV data.

```{r}
par(mfrow=c(1,2))
plotRGB(b_vrt_cloud, 3, 2, 1, stretch='lin')
plotRGB(b_vrt_cloud, 3, 2, 1, stretch='lin')
plot(r2, col = 'orange', legend = F, add = T)
par(mfrow=c(1,1))
```

Looks good! The orange area here visualises the clouds/shadow and bad pixels detected by the cloud detection algorythm within Proba-V. If you look closely, you can still observe light cloud and shadow remnants, mostly near the orange masked clouds. Altough this original cloud detection algorythm allready masked out almost all clouds, we would like to clear as many clouds (and shadow) as possible, so we have a clear reflectance of the pixels.

Lets apply the additional cloud filter! In this example we use the blue band to detect additional cloud and shadow remnants in the landscape.

```{r}
bands_select <- '(BLUE)' 
bands_sel <- paste(bands_select,'_sm.tif$', sep = "")
# Select all dates of the blue band
b_vrt <- timeVrtProbaV2(probav_sm_dir, pattern = bands_sel, vrt_name = vrt_name, tile = tiles, return_raster = T, start_date = "2014-03-06", end_date = "2015-12-06")
df_probav_sm <- timeVrtProbaV2(probav_sm_dir, pattern = bands_sel, vrt_name = vrt_name, tile = tiles[tn], return_raster = F, start_date = "2014-03-06", end_date = "2015-12-06")
out_name <- paste(getwd(),'/rsdata/probav/metrics/cloud_filter.envi', sep = "")
```
```{r, eval=F}
# set variables
# threshold for blue
blue_c_filter <- mcCalc(x=b_vrt, fun=cloud_filter, minrows = 15, mc.cores = mc.cores, logfile=logfile, out_name = out_name, overwrite = T, mc.preschedule = FALSE)
```

Lets select the same data as our false colour image from the raster brick we just created. 

```{r, eval=F}
# select date
blue_c_filter <- subset(blue_c_filter ,10)
# crop the subset to the same extent as our false colour image
blue_c_filter <- crop(x = blue_c_filter, y = e)
```

The cloud_filter function returns the Quality Control values. Meaning: "QC" is the status of observations: 0=Missing/band input QC, 1=good, 2=temporal outlier. Here we assign new values to our raster to viisualise what the SmoothLoes function detects by the extra clouds

```{r, eval=F}
# copy the data set
blue_c_filter_copy <- blue_c_filter
# assign values
blue_c_filter[blue_c_filter_copy != 2] <- NA 
blue_c_filter[blue_c_filter_copy == 2] <- 1
```
```{r, results='hide'}
blue_c_filter <- raster(paste(getwd(),'/rsdata/probav/cloudfilter/cloudfilter.tif', sep = ""))
```

Allright! Now lets plot our cloud filter!

```{r}
plot(blue_c_filter, col = 'darkred', legend = F)
```


Lets plots the original false colour again against the 2 cloud filters
```{r}
# data copy
r3 <- r2

r3[blue_c_filter == 1] <- 1
breakpoints <- c(0,2,9999)
colors <- c("darkred","orange")
par(mfrow=c(1,3), layout(matrix(1:6, 1,1, byrow = TRUE)))
plotRGB(b_vrt_cloud, 3, 2, 1, stretch='lin')
plotRGB(b_vrt_cloud, 3, 2, 1, stretch='lin')
plot(r2, col = 'orange', legend = F, add = T)
plotRGB(b_vrt_cloud, 3, 2, 1, stretch='lin')
plot(r3,breaks=breakpoints,col=colors, add = T, legend = F)
par(mfrow=c(1,1))
```


## check layers, bands, blocks and cores

```{r,eval=F}
# --- get metrics ---  #
cat(sprintf("\nlayers: %i  | bands: %s  | blocks: %i  | cores: %i\n",
            nrow(df_probav_sm), paste0(bands, collapse = " "),
            blockSize(b_vrt, minrows = minrows)$n, mc.cores))
```


## create time series using zoo

```{r,eval=T}
# Select random pixel of our raster stack
z <- zoo(c(b_vrt[50000]), getZ(b_vrt))

# use smoothloes to create time series
f <- smoothLoess(tsx = z, QC_good=NULL, dates=dates,thresholds=c(-80, Inf, -120, 120) , res_type=c("all"), span=0.3)
plot(f)
```

## get metrics from time series

We use a seasonal model approach and descriptive statistics. Per band and pixel i we derive median and percentiles and fit a liner harmonic model to the time series.
The coefficients of this model are then used as metrics for overall level and seasonality.

```{r,eval=T}
d <- getHarmMetrics(f$x,QC_good = f$QC_good ,dates = dates, sig = .95, order = 1)
d
```

## Run metrics with a raster brick output

The following function runs the getHarmMetrics to our virtual raster brick and returns the model coefficients. 

```{r, eval=F}
# No scale

# create output name on the metrics
out_name <- file.path(getwd(), paste0("rsdata/probav/metrics/",tiles[tn],"_harm_lm2_loess_03_scaled.envi"))
# set raster options to your requirements
b_metrics <- getHarmMetricsSpatial_JE(x = b_vrt, minrows = minrows, mc.cores = mc.cores,
                                      logfile=logfile,
                                      overwrite=T, span=0.3,
                                      cf_bands = c(1,2), thresholds=c(-80, Inf, -120, 120),
                                      filename = out_name, probav_sm_dir = probav_sm_dir, 
                                      order = 1, datatype="INT2S")
```


## plot the metrics

```{r,eval=F}
# metrics info
b_metrics

# band order
# names c("min", "max", "intercept", names(lmh$coefficients)[-1])

# plotting metrics
plot(b_metrics)
```

## Classification process

Lets classify! Prepare classification data
```{r}
pnt_JD <- readOGR(file.path(getwd(), "rsdata/ref_data"), "Ref_dataJD", stringsAsFactors = F)
names(pnt_JD) <- c("id", "Description", "ID_nr", "x", "y", "z", "m")
pnt_JD[,-(4:7)]
pts=as.data.frame(pnt_JD)
coordinates(pts) <- ~x+y
projection(pts) <- proj4string(pnt_JD)
pnt_JD <- pts
pnt_JD

# plot a false color image with the point reference data.
plotRGB(b_vrt_cloud, 3, 2, 1, stretch='lin')
plot(pnt_JD, add = T, col = 'red')
```

Extract cell value per reference point and create a merged dataframe

```{r}
# ----------------------- extract per tile ------------------#
tiles <- c("X18Y02") # ..., "X17Y06", "X18Y06", "X19Y06")

# run parallel processing on tiles
registerDoParallel(min(4, length(tiles)))
df_covs_tsed <- foreach(tile=tiles, .combine=rbind, .inorder = T) %dopar% {
  print(tile)
  b_metrics <- brick(paste0(getwd(), "/rsdata/probav/metrics/", tile,"_harm_lm2_loess_03_scaled.envi"))
  print("loaded")
  df_metrics_tile  <- extract(b_metrics, pnt_JD, cellnumbers=T, df=T)
  df_metrics_tile <- cbind(tile=rep(tile, nrow(df_metrics_tile)), df_metrics_tile)
  df_metrics_tile  <- na.exclude(df_metrics_tile)
  df_covs_tile <- df_metrics_tile
  print(names(df_covs_tile))
  print( nrow(df_covs_tile))
  df_covs_tile
}
```

Merged dataframe on ref data and cell values
```{r}
# JD
df_ref_JD <- pnt_JD@data[df_covs_tsed$ID,]
df_model_JD <- cbind(ID_nr=df_ref_JD$ID_nr, df_covs_tsed)
# good to save this!
```

Clear NAs
```{r}
# exclude NAs
cc <- complete.cases(df_model_JD)
table(df_model_JD$ID_nr[cc])
names(df_model_JD)
# assign names to factors
df_model_JD$LC <- factor(df_model_JD$ID_nr, labels = c("Forest","Agriculture", "Bare", "Water")) 
# only complete cases
table(df_model_JD$LC[cc])
glimpse(df_model_JD[cc, -(2:4)])
```

"Ranger is a fast implementation of random forest (Breiman 2001) or recursive partitioning, particularly suited for high dimensional data. Classification, regression, probability estimation and survival forests are supported. Classification and regression forests are implemented as in the original Random Forest (Breiman 2001), survival forests as in Random Survival Forests (Ishwaran et al. 2008). For probability estimation forests see Malley et al. (2012)." [source](https://github.com/imbs-hl/ranger)

```{r}
# run ranger on Land cover classification
cat("------- ranger ---------")
ra_JD <- ranger(LC ~., df_model_JD[cc, -(1:4)], num.trees=500, write.forest=T,
                  probability = F, num.threads=10, verbose=T, importance = "impurity")
# save the ranger model

saveRDS(ra_JD, "data/models/ra_JD_merge5_x16.rds")
print(ra_JD)
```


```{r, eval=F}
#### ------------- predict -------------------------------------------
# using ranger
model <- readRDS("data/models/ra_JD_merge5_x16.rds")
tiles <- c("X18Y02")

for (tile in tiles){
  print(paste0("--------------", tile, "-------------------"))
  # -------------------------------data----------------------------------#
  b_metrics <- brick(paste0(getwd(), "/rsdata/probav/metrics/", tile,"_harm_lm2_loess_03_scaled.envi"))
  print("---predict--------------")
  
  out_name <- paste0(getwd(), "/rsdata/probav/results/JD/pred_JD_", tile,  ".tif")

  pred_JD <- mcPredictSpatial(model,  b_metrics, b_clumps=NULL, df_clumps = NULL, type='response',
                                mc.cores = 5, ranger_threads = 1, minrows = 12, logfile = logfile,
                                datatype ="INT1U", of ="GTiff", out_name = out_name)
  
  print(pred_JD)
}
```

Check output!
```{r}
check <- raster(paste(getwd(),"/rsdata/probav/results/JD/pred_JD_X18Y02.tif", sep=""))
plot(check)
```

[creative commens](https://creativecommons.org/licenses/by-sa/4.0/) ![CC logo](https://i.creativecommons.org/l/by-sa/4.0/80x15.png)

